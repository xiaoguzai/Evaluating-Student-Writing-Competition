{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### This is a process that standardizes the examples in the training set. The main issue I see is `discourse_start` and `discourse_end` being slightly off.  ('discourse_start'和'discourse_end'有点不对劲）By standardizing and cleaning the examples, we can hopefully create consistent training data that causes an improvement in model performance.\n\n#### If `text` is the text from the file, then it would be expected that `file_text[discourse_start:discourse_end]=discourse_text` but in 44k rows, this is not the case.\n\n#### Here is an example where `file_text[discourse_start:discourse_end]!=discourse_text`\n```\ndiscourse_id = 1622992280991.0\ndiscourse_text = \"First, cell phones are a benefit and allows everyone to have access to a telephone at all times of the day.\\n\"\nfile_text[discourse_start:discourse_end]=\"rst, cell phones are a benefit and allows everyone to have access to a telephone at all times of the day.\n（这里的[discourse_start:discourse_end]为\"rst, cell phones are a benefit and allows everyone to have access to a telephone at all times of the day.）\n与它给出的真实的上文少了三个字符，因此这里需要清洗\nK\"\n```\nAfter it goes through my script: \n```\n'First, cell phones are a benefit and allows everyone to have access to a telephone at all times of the day.\\n'\n（清洗完成之后的结果）\n```\n\n#### Here is an example straight from the csv where there is a bit at the beginning that looks unecessary:\n```\ndiscourse_id = 1622489430075.0\ndiscourse_text = '. Drivers should not be able to use cell phones in any capacity while operating a motor vehicle. '\nfile_text[discourse_start:discourse_end] = '. Drivers should not be able to use cell phones in any capacity while operating a motor vehicle.\\n'\n```\nAfter it goes through my script: \n```\n'Drivers should not be able to use cell phones in any capacity while operating a motor vehicle.\\n'\n```\n\n# Please look at the following discussions for more information about this topic!\n- [Mystery Solved - Discrepancy Between PredictionString and DiscourseText](https://www.kaggle.com/c/feedback-prize-2021/discussion/297591)  \n- [Additional Information from Competition Hosts (rubric, dataset, raters, etc.)](https://www.kaggle.com/c/feedback-prize-2021/discussion/297688)\n- [Correcting the labels (Minor magic?)](https://www.kaggle.com/c/feedback-prize-2021/discussion/296778)\n\n\n#### Looking closer, there are many instances of a single character being swapped for another. In 30k out of 44k instances, one has `\"\\n\"` when the other has `\" \"` as the final character. That difference doesn't actually matter, but there are some other instances that have much worse alignment so this notebook will be my attempt at cleaning it up. \n\n#### After making these changes, about 16k `discourse_start` values change and 66k `discourse_end` values change. 😮\n\n#### Please leave a comment if you have questions or suggestions! (Some of the cells take a few minutes. I tried to use the easy multi-processing capabilities of `datasets` to speed it up as much as possible)\n<p style=\"font-size: 40px\">😊</p>","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## This section compares the text extracted using the `discourse_start` and `discourse_end` positions with `discourse_text`\n\nThe text might look the same because the only difference is \" \" and \"\\n\", so below each example I indicate which index is different between the two of them and what characters they are. `[(87, ' ', '\\n')]` means that the character at index 87 is different. In `discourse_text` it has a space and in the file text it has a newline character.","metadata":{}},{"cell_type":"code","source":"%%time\n\nimport re\nimport string\n\nimport pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm\nfrom datasets import Dataset\n\ndf = pd.read_csv(\"../input/feedback-prize-2021/train.csv\")\n\n# for each row, grab the span of text from the file using discourse_start and discourse_end\ndef get_text_by_index(example):\n    id_ = example[\"id\"]\n    start = example[\"discourse_start\"]\n    end = example[\"discourse_end\"]\n    with open(f\"../input/feedback-prize-2021/train/{id_}.txt\") as fp:\n        file_text = fp.read()\n    return {\n        \"text_by_index\": file_text[int(start) : int(end)]\n    }\n","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:04:15.678548Z","iopub.execute_input":"2022-01-07T08:04:15.678918Z","iopub.status.idle":"2022-01-07T08:04:19.764168Z","shell.execute_reply.started":"2022-01-07T08:04:15.678830Z","shell.execute_reply":"2022-01-07T08:04:19.763258Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:04:19.765964Z","iopub.execute_input":"2022-01-07T08:04:19.766226Z","iopub.status.idle":"2022-01-07T08:04:19.792017Z","shell.execute_reply.started":"2022-01-07T08:04:19.766191Z","shell.execute_reply":"2022-01-07T08:04:19.791128Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"id_ds = Dataset.from_pandas(df[[\"id\", \"discourse_start\", \"discourse_end\"]])\n\ntext_ds = id_ds.map(get_text_by_index, num_proc=4)\n#这个多线程优化很灵性\ndf[\"text_by_index\"] = text_ds[\"text_by_index\"]\n\nnot_equal_texts = df[df[\"discourse_text\"] != df[\"text_by_index\"]]\n#找出df[\"discourse_text\"]与df[\"text_by_index\"]不同的索引部分\nprint(f\"There are {len(not_equal_texts)} that are not equal\")\n#找出discourse[discourse_start:discourse_end]与后面的string不同的部分\n# Let's look at a few\ndiscourse_texts = not_equal_texts[\"discourse_text\"]\nfile_spans = not_equal_texts[\"text_by_index\"]\ndiscourse_ids = not_equal_texts[\"discourse_id\"]","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:04:19.793289Z","iopub.execute_input":"2022-01-07T08:04:19.793552Z","iopub.status.idle":"2022-01-07T08:05:02.031081Z","shell.execute_reply.started":"2022-01-07T08:04:19.793526Z","shell.execute_reply":"2022-01-07T08:05:02.030153Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"for counter, (discourse_text, file_span, discourse_id) in enumerate(\n    zip(discourse_texts, file_spans, discourse_ids)\n):\n    if counter > 5:\n        break\n\n    if len(discourse_text) != len(file_span):\n        continue\n\n    print(\"discourse_id =\", discourse_id)\n    print(\"\\n***discourse_text in train.csv***\\n\")\n    print(discourse_text)\n    print(\"\\n\"+\"-\" * 20)\n    print(\"\\n***Using discourse_start and discourse_end***\\n\")\n    print(file_span)\n\n    # Print index of character that differs between the two texts\n    print(\n        [\n            (i, char1, char2)\n            for i, (char1, char2) in enumerate(zip(discourse_text, file_span))\n            if char1 != char2\n        ]\n    )\n\n    print(\"\\n\" + \"*\" * 20 + \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:05:02.032794Z","iopub.execute_input":"2022-01-07T08:05:02.033077Z","iopub.status.idle":"2022-01-07T08:05:02.050840Z","shell.execute_reply.started":"2022-01-07T08:05:02.033043Z","shell.execute_reply":"2022-01-07T08:05:02.044820Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## At first glance it just looks like newlines and spaces are getting swapped. If we only look for instances with letters being swapped, let's see what comes out\n猛地一看这里只是换行和空格被替换了。如果我们查找字母被替换的例子，我们会发现什么结果","metadata":{}},{"cell_type":"code","source":"counter = 0\ndiscourse_texts = not_equal_texts[\"discourse_text\"]\nfile_spans = not_equal_texts[\"text_by_index\"]\ndiscourse_ids = not_equal_texts[\"discourse_id\"]\n\nfor discourse_text, file_span, discourse_id in zip(\n    discourse_texts, file_spans, discourse_ids\n):\n    if counter >= 2:\n        break\n\n    if len(discourse_text) != len(file_span):\n        continue\n\n    # Print index of character that differs between the two texts\n    diffs = [\n        (i, char1, char2)\n        for i, (char1, char2) in enumerate(zip(discourse_text, file_span))\n        if char1 != char2\n    ]\n\n    if not diffs[0][1].isalpha():\n        continue\n\n    print(\"discourse_id =\", discourse_id)\n    print(\"\\n***discourse_text in train.csv***\\n\")\n    print(discourse_text)\n    print(\"-\" * 20)\n    print(\"\\n***Using discourse_start and discourse_end***\\n\")\n    print(file_span)\n\n    # Print index of difference in char\n    print(diffs)\n\n    print(\"\\n\" + \"*\" * 20 + \"\\n\")\n    counter += 1\n","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:05:02.052974Z","iopub.execute_input":"2022-01-07T08:05:02.053203Z","iopub.status.idle":"2022-01-07T08:05:02.091003Z","shell.execute_reply.started":"2022-01-07T08:05:02.053170Z","shell.execute_reply":"2022-01-07T08:05:02.090106Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Ok now it looks like a few are misaligned by a few characters which makes it look like there are tons of characters that are different. Here is a counter of all the times the characters didn't align. Keep in mind that this includes the cases when one is a shifted version of another (like in `discourse_id=1622992466917.0`)\n看起来像很多字母都不一样，这是因为有很多字母没有对齐。注意这里是一个有着微弱移动的另外一个版本。","metadata":{}},{"cell_type":"code","source":"from collections import Counter\n\nall_diffs = []\nfor discourse_text, file_text in not_equal_texts[[\"discourse_text\", \"text_by_index\"]].values:\n    \n    if len(discourse_text) != len(file_text):\n        continue\n        \n    all_diffs.extend([(char1, char2) for char1, char2 in zip(discourse_text, file_text) if char1!=char2])\n\n    \ncounter = Counter(all_diffs)\n\ncounter.most_common(20)\n#统计一下字母无法对上的前面20个字母","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:05:02.092087Z","iopub.execute_input":"2022-01-07T08:05:02.092355Z","iopub.status.idle":"2022-01-07T08:05:03.251696Z","shell.execute_reply.started":"2022-01-07T08:05:02.092316Z","shell.execute_reply":"2022-01-07T08:05:03.250833Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## My approach to fix the incorrect `discourse_start` and `discourse_end` values\n\nThe first step is to check if we can use the entire `discourse_text` to find the starting index in the file text.\n第一步判断能否使用整个'discourse_text'去找到文件文本的开始的索引\n\nIf a match with the entire `discourse_text` string is not found, I'll take the first ~20 or so characters from `discourse_text` and see where it starts in the file text and use that as the starting point.\n如果'discourse_text'没找到，我将使用前20个'discourse_text'字符并且查看是否可以使用它们作为开始的起点。\nIf the span starts with punctuation and then text, I'll keep increasing the start index until it isn't whitespace or punctuation. This eliminates the examples that begin with a period or comma. \n如果文本span以标点符号开始，我将提升开始的位置直到它不再是空格和标点符号。这将去除掉使用空格\nIf the span ends in whitespace, I'll keep it. This whitespace could be beneficial for the model. \n如果文本span以空格结尾，我将保持它，因为空格将对模型有帮助。\nIf the span does not end in whitespace and the character after the span is punctuation or whitespace, extend the span to include it. Extending it can hopefully add useful information and it also standardizes the examples to have trailing whitespace but not leading whitespace. Adding the punctuation or whitespace would ***not*** change the `predictionstring` but it ***would*** change how the NER labeling is done.\n如果span并不以空格结束并且span后面的字符是标点符号或者空格，延伸span去包含住它。将它延伸将可能并且很有希望标准化实例","metadata":{}},{"cell_type":"code","source":"%%time\n\nPUNCTUATION = set(\".,;\")\n\ndef get_new_positions(examples):\n    \n    disc_ids = []\n    new_starts = []\n    new_ends = []\n    new_texts = []\n    \n    for id_ in examples[\"id\"]:\n    \n        with open(f\"../input/feedback-prize-2021/train/{id_}.txt\") as fp:\n            file_text = fp.read()\n\n        discourse_data = df[df[\"id\"] == id_]\n\n        discourse_ids = discourse_data[\"discourse_id\"]\n        discourse_texts = discourse_data[\"discourse_text\"]\n        discourse_starts = discourse_data[\"discourse_start\"]\n        for disc_id, disc_text, disc_start in zip(discourse_ids, discourse_texts, discourse_starts):\n            disc_text = disc_text.strip()\n            \n            matches = [x for x in re.finditer(re.escape(disc_text), file_text)]\n            #re.escape让正则表达式里面符号失去特殊含义，使用字面含义\n            #*是*，？是？，这些内容都使用字面意思\n            offset = 0\n            while len(matches) == 0 and offset < len(disc_text):\n                chunk = disc_text if offset == 0 else disc_text[:-offset]\n                matches = [x for x in re.finditer(re.escape(chunk), file_text)]\n                offset += 5\n            #前面不能匹配上的时候，从后面offset去除掉，每次去除5个字符\n            #findall与finditer函数使用的时候效果类似\n            \n            if offset >= len(disc_text):\n                print(f\"Could not find substring in {disc_id}\")\n                continue\n\n            # There are some instances when there are multiple matches, \n            # so we'll take the closest one to the original discourse_start\n            distances = [abs(disc_start-match.start()) for match in matches]\n            #如果有一个数值的时候，distances的list之中应该只有一个数值\n            #但是现在distances里面有多个数值\n            \n            idx = matches[np.argmin(distances)].start()                \n            #多个数值的时候找出离得最近的数值，变为idx\n            end_idx = idx + len(disc_text)\n\n            # if it starts with whitespace or punctuation, increase idx\n            # 开始的时候不为空格或者标点，idx增加1\n            while file_text[idx].split()==[] or file_text[idx] in PUNCTUATION:\n                idx += 1\n            \n            # if the next \n            # 结束的位置不为空格或者标点，但是结束的下一个位置为空格或者标点，继续增加一个位置\n            if (end_idx < len(file_text) and \n                (file_text[end_idx-1]!=[] or file_text[end_idx-1] not in PUNCTUATION) and \n                (file_text[end_idx].split()==[] or file_text[end_idx] in PUNCTUATION)):\n                end_idx += 1\n\n            final_text = file_text[idx:end_idx]\n            \n            disc_ids.append(disc_id)\n            new_starts.append(idx)\n            new_ends.append(idx + len(final_text))\n            #注意这里new_starts与new_ends的更新\n            new_texts.append(final_text)\n            \n    return {\n        \"discourse_id\": disc_ids,\n        \"new_start\": new_starts,\n        \"new_end\": new_ends,\n        \"text_by_new_index\": new_texts,\n    }\n\n# using Dataset will make it easy to do multi-processing        \ndataset = Dataset.from_dict({\"id\": df[\"id\"].unique()})   \n\nresults = dataset.map(get_new_positions, batched=True, num_proc=4, remove_columns=[\"id\"])\n#相当于对于df进行操作","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:05:03.253038Z","iopub.execute_input":"2022-01-07T08:05:03.253284Z","iopub.status.idle":"2022-01-07T08:08:35.316672Z","shell.execute_reply.started":"2022-01-07T08:05:03.253255Z","shell.execute_reply":"2022-01-07T08:08:35.315607Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df[\"new_start\"] = results[\"new_start\"]\ndf[\"new_end\"] = results[\"new_end\"]\ndf[\"text_by_new_index\"] = results[\"text_by_new_index\"]","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:08:35.319886Z","iopub.execute_input":"2022-01-07T08:08:35.320364Z","iopub.status.idle":"2022-01-07T08:08:35.923192Z","shell.execute_reply.started":"2022-01-07T08:08:35.320323Z","shell.execute_reply":"2022-01-07T08:08:35.922370Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Let's check how many of these new spans of text don't match the original `discourse_text` values\n","metadata":{}},{"cell_type":"markdown","source":"## 上面对于所有字符采取了去除前面的标点，如果再匹配不上前缀去除后面的标点，然后如果有重复的情况下找到离idx最近的字符串放进去，但是这里的字符串由于中间并没有被判断，所以需要进一步整个字符串是否成功匹配","metadata":{}},{"cell_type":"code","source":"new_not_equal_texts = df[df[\"discourse_text\"]!=df[\"text_by_new_index\"]].copy()\nprint(f\"There are {new_not_equal_texts['id'].nunique()} files and {len(new_not_equal_texts)} rows with mismatched spans.\")","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:08:35.924719Z","iopub.execute_input":"2022-01-07T08:08:35.925050Z","iopub.status.idle":"2022-01-07T08:08:36.134101Z","shell.execute_reply.started":"2022-01-07T08:08:35.924992Z","shell.execute_reply":"2022-01-07T08:08:36.133169Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## There are still many that don't match because I deleted some leading punctuation and added some trailing punctuation\n\n#### NOTE: One row does not match because `discourse_text` did not have the PII masked for some reason (discourse_id = 1623258656795.0). ","metadata":{}},{"cell_type":"code","source":"new_not_equal_texts[\"discourse_text\"] = new_not_equal_texts[\"discourse_text\"]\nnew_not_equal_texts[\"text_by_new_index\"] = new_not_equal_texts[\"text_by_new_index\"]\n\n# if we cutoff the last few characters, they will are more likely to be equal\nold_text = new_not_equal_texts[\"discourse_text\"].str.strip().str.slice(start=2, stop=3)\nnew_text = new_not_equal_texts[\"text_by_new_index\"].str.strip().str.slice(start=2, stop=3)\n#str.strip()把字符串头和尾部的空格以及位于头尾的\\n \\t之类的给删掉\n#str.slice(start=2,stop=3)就是取第2个字符\n\nchar_unequal_mask = old_text!=new_text\n\nunequal_texts = new_not_equal_texts[char_unequal_mask]\n\nunequal_texts[[\"discourse_text\", \"text_by_new_index\"]].sample(n=25).values","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:08:36.136378Z","iopub.execute_input":"2022-01-07T08:08:36.136708Z","iopub.status.idle":"2022-01-07T08:08:36.558846Z","shell.execute_reply.started":"2022-01-07T08:08:36.136665Z","shell.execute_reply":"2022-01-07T08:08:36.558095Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Getting predictionstring values","metadata":{}},{"cell_type":"code","source":"%%time\n\ndef find_pred_string(examples):\n    \n    new_pred_strings = []\n    discourse_ids = []\n    \n    for id_ in examples[\"id\"]:\n        with open(f\"../input/feedback-prize-2021/train/{id_}.txt\") as fp:\n            file_text = fp.read()\n\n        discourse_data = df[df[\"id\"] == id_]\n        \n        left_idxs = discourse_data[\"new_start\"]\n        right_idxs = discourse_data[\"new_end\"]\n        disc_ids = discourse_data[\"discourse_id\"]\n        \n        for left_idx, right_idx, disc_id in zip(left_idxs, right_idxs, disc_ids):\n            start_word_id = len(file_text[:left_idx].split())\n            \n            # In the event that the first character of the span is not whitespace\n            # and the character before the span is not whitespace, `len(span.split())`\n            # will need to be reduced by 1.\n            # ex: word__word___sp[an starts in the middle of a word]\n            # `len(text[:left_idx].split())==3` but it actually starts in the 3rd word \n            # which is word_id=2\n            if left_idx > 0 and file_text[left_idx].split() != [] and file_text[left_idx-1].split() != []:\n                start_word_id -= 1\n                \n            end_word_id = start_word_id + len(file_text[left_idx:right_idx].split())\n            \n            new_pred_strings.append(\" \".join(list(map(str, range(start_word_id, end_word_id)))))\n            discourse_ids.append(disc_id)\n            \n            \n    return {\n        \"new_predictionstring\": new_pred_strings,\n        \"discourse_id\": discourse_ids\n    }\n        \n#还不相等的情况下直接进行替换，将字符串切换成为file_text[left_idx:right_idx]\nid_ds = Dataset.from_pandas(df[[\"id\"]].drop_duplicates())\nnew_pred_string_ds = id_ds.map(find_pred_string, batched=True, num_proc=4, remove_columns=id_ds.column_names)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:08:36.560253Z","iopub.execute_input":"2022-01-07T08:08:36.560503Z","iopub.status.idle":"2022-01-07T08:11:21.215324Z","shell.execute_reply.started":"2022-01-07T08:08:36.560475Z","shell.execute_reply":"2022-01-07T08:11:21.214259Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# How many failed to find a substring?\n\nThere should be an empty string if no intersection is found.","metadata":{}},{"cell_type":"code","source":"df[\"new_predictionstring\"] = new_pred_string_ds[\"new_predictionstring\"]\nlen([x for x in new_pred_string_ds[\"new_predictionstring\"] if x == \"\"])","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:11:21.217230Z","iopub.execute_input":"2022-01-07T08:11:21.217476Z","iopub.status.idle":"2022-01-07T08:11:21.752390Z","shell.execute_reply.started":"2022-01-07T08:11:21.217448Z","shell.execute_reply":"2022-01-07T08:11:21.751484Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Let's compare some new and old `predictionstring` values\n\nIn all the examples I looked at, the `new_predictionstring` values looked better","metadata":{"execution":{"iopub.status.busy":"2021-12-22T22:04:26.801771Z","iopub.execute_input":"2021-12-22T22:04:26.802448Z","iopub.status.idle":"2021-12-22T22:04:26.839279Z","shell.execute_reply.started":"2021-12-22T22:04:26.802402Z","shell.execute_reply":"2021-12-22T22:04:26.838392Z"}}},{"cell_type":"code","source":"different_value_mask = df[\"new_predictionstring\"] != df[\"predictionstring\"]\n\nfor idx, row in df[different_value_mask].sample(n=5, random_state=18).iterrows():\n    file_text = open(f\"../input/feedback-prize-2021/train/{row.id}.txt\").read()\n    print(\"Old predictionstring=\", row.predictionstring)\n    print(\"New predictionstring=\", row.new_predictionstring)\n    print(\"words using old predictionstring=\", [x for i, x in enumerate(file_text.split()) if i in list(map(int, row.predictionstring.split()))])\n    print(\"words using new predictionstring=\", [x for i, x in enumerate(file_text.split()) if i in list(map(int, row.new_predictionstring.split()))])\n    print(\"discourse text=\", row.text_by_new_index)\n    print(f\"start_idx/end_idx= {row.new_start}/{row.new_end}\")\n    print(\"discourse_id=\",row.discourse_id, \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:11:21.753494Z","iopub.execute_input":"2022-01-07T08:11:21.753718Z","iopub.status.idle":"2022-01-07T08:11:22.006118Z","shell.execute_reply.started":"2022-01-07T08:11:21.753692Z","shell.execute_reply":"2022-01-07T08:11:22.005094Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## How many `discourse_start` and `discourse_end` values got modified?","metadata":{}},{"cell_type":"code","source":"print(sum(df[\"discourse_start\"].astype(int) != df[\"new_start\"]))\nprint(sum(df[\"discourse_end\"].astype(int) != df[\"new_end\"]))","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:11:22.008624Z","iopub.execute_input":"2022-01-07T08:11:22.008909Z","iopub.status.idle":"2022-01-07T08:11:22.061129Z","shell.execute_reply.started":"2022-01-07T08:11:22.008882Z","shell.execute_reply":"2022-01-07T08:11:22.060263Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Looks pretty good to me!\n\n#### But please let me know if there is something I missed because I don't want the new training set to be more detrimental than the original 😱","metadata":{}},{"cell_type":"markdown","source":"## Saving corrected information\n\nNew columns are:\n- `text_by_index` (can ignore)\n- `new_start` (replaces `discourse_start`)\n- `new_end` (replaces `discourse_end`)\n- `text_by_new_index` (replaces `discourse_text`)\n- `new_predictionstring` (replaces `predictionstring`)","metadata":{}},{"cell_type":"code","source":"df.to_csv(\"corrected_train.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T08:11:22.062229Z","iopub.execute_input":"2022-01-07T08:11:22.062511Z","iopub.status.idle":"2022-01-07T08:11:29.485145Z","shell.execute_reply.started":"2022-01-07T08:11:22.062481Z","shell.execute_reply":"2022-01-07T08:11:29.484175Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Hopefully this makes our models better! I know it can be confusing, so please comment and I'll do my best to answer your quesions!\n\n<p style=\"font-size: 40px\">😊</p>","metadata":{}}]}